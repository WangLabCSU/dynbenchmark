#' @importFrom sigmoid sigmoid
.benchmark_aggregate_normalisation <- list(
  scalesigmoid = function (xnona, xnazero = xnona, multiplier = 1) {
    vars <- list(
      trafo_fun = "scalesigmoid",
      mean = mean(xnona),
      sd = sd(xnona),
      multiplier = multiplier
    )
    y <- (xnazero - vars[["mean"]]) / vars[["sd"]] * vars[["multiplier"]]

    list(
      y = sigmoid::sigmoid(y),
      vars = vars
    )
  },
  scaletanh = function (xnona, xnazero = xnona, multiplier = 1) {
    vars <- list(
      trafo_fun = "scaletanh",
      mean = mean(xnona),
      sd = sd(xnona),
      multiplier = multiplier
    )
    y <- (xnazero - vars[["mean"]]) / vars[["sd"]] * vars[["multiplier"]]

    list(
      y = tanh(y),
      vars = vars
    )
  },
  minmax = function (xnona, xnazero = xnona) {
    vars <- list(
      trafo_fun = "minmax",
      min = min(xnona),
      max = max(xnona)
    )
    y <- (xnazero - vars[["min"]]) / (vars[["max"]] - vars[["min"]])

    list(
      y = y,
      vars = vars
    )
  },
  percent_rank = function(xnona, xnazero = xnona) {
    list(
      y = percent_rank(xnazero),
      vars = list(
        trafo_fun = "percent_rank"
      )
    )
  },
  normal = function(xnona, xnazero = xnona) {
    vars <- list(
      trafo_fun = "normal",
      mean = mean(xnona),
      sd = sd(xnona)
    )
    y <- (xnazero - vars[["mean"]]) / vars[["sd"]]

    list(
      y = pnorm(y),
      vars = vars
    )
  },
  none = function(xnona, xnazero = xnona) {
    list(
      y = xnazero,
      vars = list(trafo_fun = "none")
    )
  }
)

#' Normalisation and aggregation function
#'
#' @param data Data as generated by the `06-benchmark/2-retrieve_results.R` script
#' @param metrics Metrics to normalise
#' @param norm_fun Which normalisation to use
#' @param mean_fun Which mean function to use
#' @param mean_weights Which metrics to use for the calculation of the mean, and which weights
#' @param dataset_source_weights The weights of the dataset sources
#'
#' @export
benchmark_aggregate <- function(
  data,
  metrics = c("correlation", "him", "featureimp_wcor", "F1_branches"),
  norm_fun = "normal",
  mean_fun = "geometric",
  mean_weights = set_names(rep(1, length(metrics)), metrics),
  dataset_source_weights = get_default_dataset_source_weights()
) {
  # add a few columns
  data <- data %>% mutate(
    pct_errored = (error_status != "no_error") + 0,
    pct_time_limit = (error_status == "time_limit") + 0,
    pct_memory_limit = (error_status == "memory_limit") + 0,
    pct_execution_error = (error_status == "execution_error") + 0,
    pct_method_error = (error_status == "method_error") + 0
  )

  # clip values
  data <- data %>% mutate_at(metrics, function(x) ifelse(is.na(x), 0, x) %>% pmax(0) %>% pmin(1))

  # check normalise parameter
  if (is.character(norm_fun)) {
    do_norm <- norm_fun != "none"
    norm_fun <- .benchmark_aggregate_normalisation[[match.arg(norm_fun, choices = names(.benchmark_aggregate_normalisation))]]
  }

  # check dataset source weights
  if (any(!data$dataset_source %in% names(dataset_source_weights))) {
    stop("Some dataset sources have no weight!")
  }

  if (do_norm) {
    dataset_ids <- unique(data$dataset_id)

    preproc_out <- map(dataset_ids, function(dataset_id) {
      data_did <- data %>% filter(dataset_id == !!dataset_id)

      outs <- map(metrics, function(mid) {
        x <- data_did[[mid]]

        x[x < 0] <- 0
        x[x > 1] <- 1

        xnona <- x[!is.na(x)]
        xnazero <- ifelse(is.na(x), 0, x)

        out <-
          if (length(xnazero) == 1 || all(xnazero == 0)) {
            .benchmark_aggregate_normalisation[["none"]](xnona, xnazero)
          } else {
            norm_fun(xnona, xnazero)
          }

        out$value <- set_names(list(out$y), paste0("norm_", mid))
        out$vars <- out$vars %>% as_tibble() %>% mutate(metric = mid)
        out$y <- NULL

        out
      })

      values <- map(outs, "value") %>% unlist(recursive = FALSE) %>% as_tibble()
      vars <- map_df(outs, "vars") %>% mutate(dataset_id) %>% select(dataset_id, metric, everything())

      data_did <- bind_cols(data_did[, setdiff(colnames(data_did), colnames(values))], values)

      lst(data = data_did, norm_vars = vars)
    })
    data <- map_df(preproc_out, "data")
    norm_vars <- map_df(preproc_out, "norm_vars")
    names(mean_weights) <- paste0("norm_", names(mean_weights))
  } else {
    norm_vars <- tibble(
      dataset_id = character(0),
      metric_id = character(0)
    )
  }

  # check mean parameter
  if (is.character(mean_fun)) {
    mean_fun <- switch(
      mean_fun,
      geometric = dynutils::calculate_geometric_mean,
      harmonic = dynutils::calculate_harmonic_mean,
      arithmetic = dynutils::calculate_arithmetic_mean
    )
  }

  calc_mean <- function(df) {
    lis <- df %>% select(!!names(mean_weights)) %>% as.list()
    df$overall <- mean_fun(lis, weights = mean_weights)
    df
  }

  # calculate mean between metrics
  data <- data %>%
    calc_mean()

  # aggregate over replicates
  data_repl <- data %>%
    group_by(method_id, method_name, dataset_id, param_id, dataset_trajectory_type, dataset_source) %>%
    select(-repeat_ix) %>%
    summarise_if(is.numeric, mean) %>%
    ungroup() %>%
    mutate(
      pct_method_error_all = (pct_method_error == 1) + 0,
      pct_method_error_stoch = pct_method_error - pct_method_error_all
    ) %>%
    calc_mean()

  # process source grouped evaluation
  data_source <- data_repl %>%
    group_by(method_id, method_name, param_id, dataset_trajectory_type, dataset_source) %>%
    summarise_if(is.numeric, mean) %>%
    ungroup() %>%
    calc_mean()

  # process overall evaluation
  data_method <- data_source %>%
    gather(metric, value, -method_id:-dataset_source) %>%
    mutate(dataset_weight = dataset_source_weights[dataset_source]) %>%
    group_by(method_id, method_name, param_id, dataset_trajectory_type, metric) %>%
    summarise(value = sum(value * dataset_weight) / sum(dataset_weight)) %>%
    spread(metric, value) %>%
    ungroup() %>%
    calc_mean() %>%
    mutate(
      dataset_source = "mean"
    )

  data_aggregations <-
    bind_rows(data_source, data_method) %>% {
      df <- .
      bind_rows(
        df,
        df %>%
          group_by(method_id, method_name, param_id, dataset_source) %>%
          summarise_if(is.numeric, mean) %>%
          ungroup() %>%
          calc_mean() %>%
          mutate(dataset_trajectory_type = "overall")
      )
    }

  lst(
    data,
    data_aggregations,
    data_transformation = norm_vars
  )
}


get_default_dataset_source_weights <- function() {
  if (tryCatch(is.character(get_dynbenchmark_folder()), error = function(e) FALSE) && file.exists(result_file("dataset_source_weights.rds", "06-benchmark"))) {
    read_rds(result_file("dataset_source_weights.rds", "06-benchmark"))
  } else {
    warning("Dataset source weights not found, using defaults")
    c("real/gold" = 5, "real/silver" = 1, "synthetic/dyngen" = 5, "synthetic/dyntoy" = 1, "synthetic/prosstt" = 1, "synthetic/splatter" = 1)
  }
}

#' @param datasets Tibble with dataset_id, dataset_source and dataset_trajectory_type
#' @rdname benchmark_aggregate
#' @export
get_dataset_weighting <- function(datasets, dataset_source_weights = get_default_dataset_source_weights()) {
  testthat::expect_true(all(c("dataset_id", "dataset_source", "dataset_trajectory_type") %in% colnames(datasets)))

  datasets %>%
    distinct(dataset_id, dataset_source, dataset_trajectory_type) %>%
    mutate(weight = 1) %>%
    group_by(dataset_trajectory_type) %>%
    mutate(weight = weight / n()) %>%
    ungroup() %>%
    group_by(dataset_source) %>%
    mutate(weight = weight / n() * dataset_source_weights[dataset_source]) %>%
    ungroup() %>%
    mutate(weight = weight / sum(weight)) %>%
    select(dataset_id, weight)
}
